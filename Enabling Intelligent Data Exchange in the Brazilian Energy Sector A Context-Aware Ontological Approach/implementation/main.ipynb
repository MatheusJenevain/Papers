{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import os\n",
    "from owlready2 import get_ontology\n",
    "from owlready2 import sync_reasoner_hermit\n",
    "import traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 'Neutral' loaded successfully.\n",
      "Class 'Receiver' loaded successfully.\n",
      "Class 'Sender' loaded successfully.\n",
      "Class 'actor' loaded successfully.\n",
      "Class 'actorRole' loaded successfully.\n",
      "Class 'actorType' loaded successfully.\n",
      "Class 'byContext' loaded successfully.\n",
      "Class 'company' loaded successfully.\n",
      "Class 'companyOwned' loaded successfully.\n",
      "Class 'context' loaded successfully.\n",
      "Class 'distributedEnergyResource' loaded successfully.\n",
      "Class 'energySector' loaded successfully.\n",
      "Class 'exchangedData' loaded successfully.\n",
      "Class 'exchangedDataLog' loaded successfully.\n",
      "Class 'individual' loaded successfully.\n",
      "Class 'industrySector' loaded successfully.\n",
      "Class 'language' loaded successfully.\n",
      "Class 'meaning' loaded successfully.\n",
      "Class 'organization' loaded successfully.\n",
      "Class 'powerPlant' loaded successfully.\n",
      "Class 'privatelyOwned' loaded successfully.\n",
      "Class 'sector' loaded successfully.\n",
      "Class 'term' loaded successfully.\n",
      "Class 'termContent' loaded successfully.\n",
      "Class 'userAtentionFocus' loaded successfully.\n",
      "All classes loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# loading ontologies\n",
    "directory = 'C:\\\\Users\\\\Matheus\\\\Documents\\\\GitHub\\\\Papers\\\\Enabling Intelligent Data Exchange in the Brazilian Energy Sector A Context-Aware Ontological Approach\\\\ontology\\\\imports'\n",
    "filename = 'oec-extracted.owl'\n",
    "\n",
    "# Create the full file path\n",
    "file_path = os.path.join(directory, filename)\n",
    "\n",
    "# Initialize variables\n",
    "stop_execution = False  # Flag to control execution flow\n",
    "all_classes_loaded = True  # Flag to track successful loading\n",
    "\n",
    "try:\n",
    "    # Load the ontology directly\n",
    "    onto = get_ontology(\"file://\" + file_path).load()\n",
    "    # Access classes in the ontology\n",
    "    for cls in onto.classes():\n",
    "        if stop_execution:\n",
    "            break\n",
    "        try:\n",
    "            # Access instances for each class\n",
    "            list(cls.instances())\n",
    "            print(f\"Class '{cls.name}' loaded successfully.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred while accessing class '{cls.name}':\")\n",
    "            traceback.print_exc()\n",
    "            stop_execution = True\n",
    "\n",
    "    # Check if all classes were loaded successfully\n",
    "    if all_classes_loaded and not stop_execution:\n",
    "        print(\"All classes loaded successfully!\")\n",
    "\n",
    "except Exception as e:\n",
    "    # Print the traceback if an error occurs during initial loading\n",
    "    print(\"Error occurred during initial ontology loading:\")\n",
    "    traceback.print_exc()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "* Owlready2 * Running HermiT...\n",
      "    java -Xmx2000M -cp c:\\ProgramData\\anaconda3\\Lib\\site-packages\\owlready2\\hermit;c:\\ProgramData\\anaconda3\\Lib\\site-packages\\owlready2\\hermit\\HermiT.jar org.semanticweb.HermiT.cli.CommandLine -c -O -D -I file:///C:/Users/Matheus/AppData/Local/Temp/tmpi8mv8d9p\n",
      "* Owlready2 * HermiT took 0.43159008026123047 seconds\n",
      "* Owlready * (NB: only changes on entities loaded in Python are shown, other changes are done but not listed)\n"
     ]
    }
   ],
   "source": [
    "#sync reasoner\n",
    "try:\n",
    "    with onto:\n",
    "        sync_reasoner_hermit()\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actorHasRole\n",
      "actorHasType\n",
      "actorHasContext\n",
      "actorHasOrganization\n",
      "actorHasSector\n",
      "contextDefinedByActorRole\n",
      "contextDefinedByActorType\n",
      "contextDefinedBySector\n",
      "contextUserAttentionFocus\n",
      "exchangedDataHasContext\n",
      "exchangedDataHasLog\n",
      "exchangedDataHasReceiver\n",
      "exchangedDataHasSender\n",
      "exchangedDataHasTerm\n",
      "termHasLanguage\n",
      "termHasMeaningByContext\n",
      "termHasMeaningByLiteralDefinition\n",
      "termHasWrittenContent\n"
     ]
    }
   ],
   "source": [
    "#for c in onto.classes(): print(c.name)\n",
    "for c in onto.object_properties(): print(c.name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object Property 'termHasMeaningByContext' inferred on individual 'ContextDERHousehold' because of 'TermNetGridConnectionDERHousehold'\n",
      "Object Property 'termHasMeaningByContext' inferred on individual 'ContextDERHousehold' because of 'TermStorageMeaningEnergyCompany'\n",
      "Object Property 'exchangedDataHasTerm' inferred on individual 'ExchangedTermGridConnection' because of 'ExchangedDataHouseholdToCompany'\n",
      "Object Property 'exchangedDataHasTerm' inferred on individual 'ExchangedDataHouseholdToCompany' because of 'ExchangedTermStorage'\n",
      "Object Property 'exchangedDataHasReceiver' inferred on individual 'ActorEnergyCompany' because of 'ExchangedDataHouseholdToCompany'\n",
      "Object Property 'contextDefinedByActorType' inferred on individual 'ContextDERHousehold' because of 'ActorDERHousehold'\n",
      "Object Property 'actorHasType' inferred on individual 'ActorTypeDER' because of 'ActorDERHousehold'\n",
      "Object Property 'exchangedDataHasTerm' inferred on individual 'ExchangedDataHouseholdToCompany' because of 'ExchangedTermGridConnection'\n",
      "Object Property 'exchangedDataHasSender' inferred on individual 'ActorDERHousehold' because of 'ExchangedDataHouseholdToCompany'\n",
      "Object Property 'termHasWrittenContent' inferred on individual 'TermStorageMeaningDERHousehold' because of 'ExchangedTermStorage'\n",
      "Object Property 'exchangedDataHasTerm' inferred on individual 'ExchangedDataHouseholdToCompany' because of 'ExchangedTermNetMetering'\n",
      "Object Property 'termHasWrittenContent' inferred on individual 'ExchangedTermStorage' because of 'TermStorageMeaningDERHousehold'\n",
      "Object Property 'actorHasContext' inferred on individual 'ContextDERHousehold' because of 'ActorDERHousehold'\n",
      "Object Property 'exchangedDataHasTerm' inferred on individual 'ExchangedTermStorage' because of 'ExchangedDataHouseholdToCompany'\n",
      "Object Property 'exchangedDataHasTerm' inferred on individual 'ExchangedTermNetMetering' because of 'ExchangedDataHouseholdToCompany'\n",
      "Object Property 'termHasMeaningByContext' inferred on individual 'ContextDERHousehold' because of 'TermStorageMeaningDERHousehold'\n"
     ]
    }
   ],
   "source": [
    "# Get inferred object properties and their usage\n",
    "inferred_properties = set()\n",
    "\n",
    "for prop in onto.object_properties():\n",
    "    try:\n",
    "        for subj, obj in prop.get_relations():\n",
    "            inferred_properties.add((prop, subj, obj))\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while processing object property '{prop.name}': {e}\")\n",
    "\n",
    "# Print inferred object properties and their usage\n",
    "for prop, subj, obj in inferred_properties:\n",
    "    try:\n",
    "        subj_type = \"Class\" if subj in onto.classes() else \"Individual\" if subj in onto.individuals() else \"Unknown\"\n",
    "        obj_type = \"Class\" if obj in onto.classes() else \"Individual\" if obj in onto.individuals() else \"Unknown\"\n",
    "\n",
    "        print(f\"Object Property '{prop.name}' inferred on {obj_type.lower()} '{obj.name}' because of '{subj.name}'\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while formatting output: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ontology is consistent.\n"
     ]
    }
   ],
   "source": [
    "#check inconsistensies\n",
    "inconsistencies = list(onto.inconsistent_classes())\n",
    "if inconsistencies:\n",
    "    print(\"Ontology is inconsistent!\")\n",
    "    print(\"Inconsistencies:\")\n",
    "    for inconsistency in inconsistencies:\n",
    "        print(f\"Inconsistency found involving: {inconsistency}\")\n",
    "else:\n",
    "    print(\"Ontology is consistent.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('savings_bank.n.02') a container (usually with a slot in the top) for keeping money at home\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Matheus\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Matheus\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.wsd import lesk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "\n",
    "sentence = \"I went to the bank to deposit some money.\"\n",
    "tokenized_sentence = word_tokenize(sentence)\n",
    "word = 'bank'\n",
    "\n",
    "# Perform Word Sense Disambiguation for 'bank' in the given sentence\n",
    "meaning = lesk(tokenized_sentence, word)\n",
    "print(meaning, meaning.definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual or data property not found in the ontology.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Check for the individual and data property labels\n",
    "individual = onto.search_one(label=\"TermStorageMeaningDERHousehold\")\n",
    "data_property = onto.search_one(label=\"LabelTermContentString\")\n",
    "\n",
    "if individual and data_property:\n",
    "    # Define the individual and data property IRIs\n",
    "    individual_iri = individual.iri\n",
    "    data_property_iri = data_property.iri\n",
    "\n",
    "    # Define the SPARQL query\n",
    "    query = f\"\"\"\n",
    "        PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "        PREFIX : <http://www.semanticweb.org/matheus/ontologies/2023/10/oec-extracted>  # Replace with your ontology's base IRI\n",
    "        SELECT ?content\n",
    "        WHERE {{\n",
    "            <{individual_iri}> :{data_property_iri} ?content .\n",
    "        }}\n",
    "    \"\"\"\n",
    "\n",
    "    # Execute SPARQL query\n",
    "    results = onto.query(query)\n",
    "\n",
    "    # Print results\n",
    "    for result in results:\n",
    "        print(f\"Value of termContentString for TermStorageMeaningDERHousehold: {result[0]}\")\n",
    "else:\n",
    "    print(\"Individual or data property not found in the ontology.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No existing entity for IRI 'http://www.semanticweb.org/matheus/ontologies/2023/10/oec-extracted#YourDesiredClass'! (use error_on_undefined_entities=False to accept unknown entities in SPARQL queries)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[62], line 14\u001b[0m\n\u001b[0;32m      1\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124m    PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124m    PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;124m    }\u001b[39m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Execute the SPARQL query\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m results \u001b[38;5;241m=\u001b[39m onto\u001b[38;5;241m.\u001b[39mworld\u001b[38;5;241m.\u001b[39msparql(query)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m results:\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28mprint\u001b[39m(row)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\owlready2\\namespace.py:466\u001b[0m, in \u001b[0;36mWorld.sparql\u001b[1;34m(self, sparql, params, error_on_undefined_entities, spawn)\u001b[0m\n\u001b[0;32m    465\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msparql\u001b[39m(\u001b[38;5;28mself\u001b[39m, sparql, params \u001b[38;5;241m=\u001b[39m (), error_on_undefined_entities \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, spawn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m--> 466\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_sparql(sparql, error_on_undefined_entities)\u001b[38;5;241m.\u001b[39mexecute(params, \u001b[38;5;28;01mNone\u001b[39;00m, spawn)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\owlready2\\namespace.py:471\u001b[0m, in \u001b[0;36mWorld._prepare_sparql\u001b[1;34m(self, sparql, error_on_undefined_entities)\u001b[0m\n\u001b[0;32m    468\u001b[0m \u001b[38;5;129m@lru_cache\u001b[39m(maxsize \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1024\u001b[39m)\n\u001b[0;32m    469\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_prepare_sparql\u001b[39m(\u001b[38;5;28mself\u001b[39m, sparql, error_on_undefined_entities):\n\u001b[0;32m    470\u001b[0m   \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mowlready2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparql\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmain\u001b[39;00m\n\u001b[1;32m--> 471\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m owlready2\u001b[38;5;241m.\u001b[39msparql\u001b[38;5;241m.\u001b[39mmain\u001b[38;5;241m.\u001b[39mTranslator(\u001b[38;5;28mself\u001b[39m, error_on_undefined_entities)\u001b[38;5;241m.\u001b[39mparse(sparql)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\owlready2\\sparql\\main.py:61\u001b[0m, in \u001b[0;36mTranslator.parse\u001b[1;34m(self, sparql)\u001b[0m\n\u001b[0;32m     59\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mescape_mark \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mç\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     60\u001b[0m CURRENT_TRANSLATOR\u001b[38;5;241m.\u001b[39mset(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m---> 61\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmain_query \u001b[38;5;241m=\u001b[39m PARSER\u001b[38;5;241m.\u001b[39mparse(LEXER\u001b[38;5;241m.\u001b[39mlex(sparql))\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinalize()\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\owlready2\\rply.py:416\u001b[0m, in \u001b[0;36mLRParser.parse\u001b[1;34m(self, tokenizer, state)\u001b[0m\n\u001b[0;32m    414\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlr_table\u001b[38;5;241m.\u001b[39mdefault_reductions[current_state]:\n\u001b[0;32m    415\u001b[0m   t \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlr_table\u001b[38;5;241m.\u001b[39mdefault_reductions[current_state]\n\u001b[1;32m--> 416\u001b[0m   current_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reduce_production(\n\u001b[0;32m    417\u001b[0m     t, symstack, statestack, state\n\u001b[0;32m    418\u001b[0m   )\n\u001b[0;32m    419\u001b[0m   \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m    421\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lookahead \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\owlready2\\rply.py:465\u001b[0m, in \u001b[0;36mLRParser._reduce_production\u001b[1;34m(self, t, symstack, statestack, state)\u001b[0m\n\u001b[0;32m    463\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m symstack[start:]\n\u001b[0;32m    464\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m statestack[start:]\n\u001b[1;32m--> 465\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m state \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: value \u001b[38;5;241m=\u001b[39m p\u001b[38;5;241m.\u001b[39mfunc(targ)\n\u001b[0;32m    466\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:             value \u001b[38;5;241m=\u001b[39m p\u001b[38;5;241m.\u001b[39mfunc(state, targ)\n\u001b[0;32m    467\u001b[0m symstack\u001b[38;5;241m.\u001b[39mappend(value)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\owlready2\\sparql\\parser.py:1019\u001b[0m, in \u001b[0;36mf\u001b[1;34m(p)\u001b[0m\n\u001b[0;32m   1017\u001b[0m p\u001b[38;5;241m.\u001b[39mname   \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIRI\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1018\u001b[0m p\u001b[38;5;241m.\u001b[39mvalue  \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (translator\u001b[38;5;241m.\u001b[39mexpand_prefix(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m prefix), name)\n\u001b[1;32m-> 1019\u001b[0m p\u001b[38;5;241m.\u001b[39mstorid \u001b[38;5;241m=\u001b[39m p\u001b[38;5;241m.\u001b[39msql \u001b[38;5;241m=\u001b[39m translator\u001b[38;5;241m.\u001b[39mabbreviate(p\u001b[38;5;241m.\u001b[39mvalue)\n\u001b[0;32m   1020\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m p\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\owlready2\\sparql\\main.py:250\u001b[0m, in \u001b[0;36mTranslator.abbreviate\u001b[1;34m(self, entity)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_on_undefined_entities:\n\u001b[0;32m    249\u001b[0m   r \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mworld\u001b[38;5;241m.\u001b[39m_abbreviate(entity, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m--> 250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m r \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo existing entity for IRI \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m! (use error_on_undefined_entities=False to accept unknown entities in SPARQL queries)\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m entity)\n\u001b[0;32m    251\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m r\n\u001b[0;32m    252\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: No existing entity for IRI 'http://www.semanticweb.org/matheus/ontologies/2023/10/oec-extracted#YourDesiredClass'! (use error_on_undefined_entities=False to accept unknown entities in SPARQL queries)"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "    PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "    PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "    PREFIX : <http://www.semanticweb.org/matheus/ontologies/2023/10/oec-extracted#>\n",
    "\n",
    "    SELECT ?individual ?label\n",
    "    WHERE {\n",
    "        ?individual rdf:type/rdfs:subClassOf* :YourDesiredClass .\n",
    "        ?individual rdfs:label ?label .\n",
    "    }\n",
    "\"\"\"\n",
    "\n",
    "# Execute the SPARQL query\n",
    "results = onto.world.sparql(query)\n",
    "for row in results:\n",
    "    print(row)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
